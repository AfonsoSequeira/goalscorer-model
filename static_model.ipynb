{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aacb2406",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import scipy\n",
    "import glob\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "import os\n",
    "from sklearn.metrics import r2_score\n",
    "from scipy.stats import binom, poisson, nbinom, expon, gamma\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import warnings\n",
    "import statsmodels.api as sm\n",
    "from sklearn import linear_model\n",
    "import sys\n",
    "from catboost import CatBoostRegressor\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "sys.path.insert(0,'C:/MyDevelopment/Goalscorers')\n",
    "from helper_functions import *\n",
    "import data_cleaning as dc\n",
    "import feature_engineering as fe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "74f6ec6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "goal_exps = pd.read_csv(\"C:/MyDevelopment/Goalscorers/goal_expectancies/fbref_matched_expectancies.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2cb1e52a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pre_processed_data(seasons_to_load, leagues_to_load, data_exp):\n",
    "    data = dc.load_data(seasons_to_load, leagues_to_load)\n",
    "    data = dc.add_datetime(data)\n",
    "    data = dc.add_opposite_team(data)\n",
    "    data = dc.map_position(data)\n",
    "    data = dc.add_npg(data)\n",
    "    data = dc.add_year_week(data)\n",
    "    data = dc.add_goal_expectancies(data,data_exp)\n",
    "    data = dc.add_supremacy(data)\n",
    "    data = dc.add_npxg_per_minute(data)\n",
    "    data = dc.add_team_scored_and_conceded_npxg(data)\n",
    "    data = dc.add_solo_striker_position(data)\n",
    "    data = dc.add_main_opposing_gk(data)\n",
    "    data = dc.remove_gk(data)\n",
    "    data = dc.drop_NAs(data)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ce0db0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_data = get_pre_processed_data(None, None, goal_exps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1e1cf973",
   "metadata": {},
   "outputs": [],
   "source": [
    "##feature engineering\n",
    "#map npxg to be non-zero\n",
    "data = preprocessed_data.copy(deep=True)\n",
    "\n",
    "#add average npxg per minute features \n",
    "data = fe.add_player_avg_feature(data, \"npxg_per_min\", 5)\n",
    "data = fe.add_player_avg_feature(data, \"npxg_per_min\", 10)\n",
    "\n",
    "#add average npxg per minute / average team conceded npxg features, for 2,6,10 previous appearances\n",
    "data, team_data = fe.add_team_avg_feature(data, \"team_conceded_npxg\", 5)\n",
    "data[\"npxg_per_min_over_squad_opp_avg\"] = data.npxg_per_min - data.avg_team_conceded_npxg_l5 \n",
    "data = fe.add_player_avg_feature(data, \"npxg_per_min_over_squad_opp_avg\", 5)\n",
    "data = fe.add_player_avg_feature(data, \"npxg_per_min_over_squad_opp_avg\", 10)\n",
    "\n",
    "#add average touches in att_3rd and touches in att_pen_area in last 5 games\n",
    "data[\"touches_att_3rd_per_min\"] = data.touches_att_3rd/data.minutes\n",
    "data[\"touches_att_pen_area_per_min\"] = data.touches_att_pen_area/data.minutes\n",
    "\n",
    "data = fe.add_player_avg_feature(data, \"touches_att_3rd_per_min\", 5)\n",
    "data = fe.add_player_avg_feature(data, \"touches_att_pen_area_per_min\", 5)\n",
    "data.npxg = data.npxg.transform(lambda x: 0.0001 if x == 0 else x)\n",
    "\n",
    "#add features\n",
    "data[\"frac_90\"] = data.minutes/90\n",
    "data[\"ln_frac_90\"] = np.log(data.frac_90)\n",
    "data[\"ln_frac_90_start\"] = data.ln_frac_90 * data.start\n",
    "data[\"ln_frac_90_not_start\"] = data.ln_frac_90 * (1.0 - data.start)\n",
    "data[\"goal_exp_2\"] = data.goal_exp ** 2\n",
    "data[\"supremacy_2\"] = data.supremacy ** 2\n",
    "data[\"is_home\"] = np.where(data.squad == data.home_team, 1, 0)\n",
    "data[\"start\"] = np.where(data.start == True, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3e1674c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(442937, 72)\n",
      "(442937, 89)\n"
     ]
    }
   ],
   "source": [
    "print(preprocessed_data.shape)\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a6915e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get_week_difference\n",
    "def get_week_difference(data, current_year, current_week):\n",
    "    def func(row):\n",
    "        d = (current_year - row[\"year\"]) * 52 + (current_week - row[\"week\"])\n",
    "        assert(d >= 0)\n",
    "        return d\n",
    "        \n",
    "    diff = data.apply(func, axis = 1)\n",
    "    return diff\n",
    "\n",
    "#get training weights\n",
    "def get_weights(data, year, week, decay_factor):\n",
    "    if decay_factor != None:\n",
    "        week_diff = get_week_difference(data, year, week)\n",
    "        weights = np.exp(-decay_factor*week_diff)\n",
    "    else:\n",
    "        weights = np.full(len(data), 1.0)\n",
    "        \n",
    "    return weights\n",
    "\n",
    "#standardize\n",
    "def standardize(X, cols_to_standardize, scaler=None):\n",
    "    \n",
    "    if scaler==None:\n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit(X[cols_to_standardize])\n",
    "    \n",
    "    X[cols_to_standardize] = scaler.transform(X[cols_to_standardize])\n",
    "    return X, scaler\n",
    "\n",
    "#estimate gamma parameters\n",
    "def get_gamma_parameters(y_train, train_preds, test_preds, n_features):\n",
    "            \n",
    "    def estimate_x2_scale(y, mu, n_sample, dof):\n",
    "        resid = np.power(y- mu, 2)\n",
    "        variance = mu ** 2\n",
    "        df_residuals = n_sample - dof\n",
    "        return np.sum(resid / variance) / df_residuals\n",
    "\n",
    "    inv_shape_param =  estimate_x2_scale(y_train, train_preds, len(y_train), n_features)\n",
    "    shape_from_model = 1/inv_shape_param\n",
    "\n",
    "    scales = [m_i /shape_from_model for m_i in test_preds]\n",
    "    shapes = np.full(len(scales), shape_from_model)\n",
    "\n",
    "    return scales, shapes\n",
    "\n",
    "#get log likelihoods given expectancies\n",
    "def calculate_log_likelihood(y_true, parameters, distribution='Poisson',individual_scores=False):\n",
    "    assert(len(y_true) == len(parameters[0]))\n",
    "    if distribution =='Poisson' or distribution == 'Exponential':\n",
    "        assert(len(parameters) == 1)\n",
    "    elif distribution =='Gamma':\n",
    "        assert(len(parameters) == 2)\n",
    "    \n",
    "    if distribution=='Poisson':\n",
    "        expectancies = parameters[0]\n",
    "        probs = poisson.pmf(y_true, expectancies)\n",
    "        ind_log_ll = np.log(probs)\n",
    "        \n",
    "    elif distribution=='Exponential':\n",
    "        expectancies = parameters[0]\n",
    "        probs = expon.pdf(y_true, scale= 1/expectancies)\n",
    "        ind_log_ll = np.maximum(-10000,np.log(probs))\n",
    "        \n",
    "    elif distribution=='Gamma':\n",
    "        scales = parameters[0]\n",
    "        shapes = parameters[1]\n",
    "        probs = gamma.pdf(y_true, a = shapes,scale=scales)\n",
    "        ind_log_ll = np.maximum(-10000,np.log(probs))\n",
    "        \n",
    "    else:\n",
    "        raise ValueError('Invalid distribution argument passed.')\n",
    "        \n",
    "    \n",
    "    log_ll = np.sum(ind_log_ll)\n",
    "    avg_log_ll = log_ll/len(probs)\n",
    "    \n",
    "    if individual_scores == False:\n",
    "        return log_ll, avg_log_ll\n",
    "    else:\n",
    "        return ind_log_ll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e39dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d053769a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ohe(data, categorical_columns) -> pd.DataFrame:\n",
    "    data_ohe = data.copy(deep=True)\n",
    "    return (\n",
    "        data_ohe\n",
    "        .join(pd.get_dummies(data[categorical_columns].astype(str), dtype=int))\n",
    "    )\n",
    "\n",
    "def get_features(data, cols_to_ohe):\n",
    "    features = [\n",
    "        'goal_exp', 'supremacy', 'frac_90'\n",
    "    ]\n",
    "    \n",
    "    for col in cols_to_ohe:\n",
    "        new_features = [f\"{col}_{val}\" for val in data[col].unique()]\n",
    "        features = features + new_features\n",
    "    \n",
    "    return features\n",
    "\n",
    "#target_variable = 'npxg'\n",
    "target_variable_cat = 'npg'\n",
    "\n",
    "cols_to_standardize = [\n",
    "    'goal_exp',\n",
    "    'supremacy',\n",
    "    'ln_frac_90_start',\n",
    "    'ln_frac_90_not_start',\n",
    "    'avg_npxg_per_min_l5',\n",
    "    'avg_npxg_per_min_l10',\n",
    "    'avg_team_conceded_npxg_l5',\n",
    "    'avg_npxg_per_min_over_squad_opp_avg_l5',\n",
    "    'avg_npxg_per_min_over_squad_opp_avg_l10',\n",
    "    'avg_touches_att_3rd_per_min_l5',\n",
    "    'avg_touches_att_pen_area_per_min_l5',\n",
    "]\n",
    "\n",
    "cols_to_ohe = [\n",
    "    'position',\n",
    "    'squad_opp',\n",
    "    'player',\n",
    "    'gk_opp'\n",
    "]\n",
    "\n",
    "cols_other = [\n",
    "    'start',\n",
    "    'is_home'\n",
    "]\n",
    "\n",
    "#data_model = ohe(data, cols_to_ohe)\n",
    "data_catboost = data.copy()\n",
    "\n",
    "#model_features = get_features(data_model, cols_to_ohe)\n",
    "catboost_features = cols_other + cols_to_standardize + cols_to_ohe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c763efd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_catboost[catboost_features].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "838f029b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data = data_model[(data.season == '2017-2018') | (data.season == '2018-2019') | (data.season == '2019-2020')]\n",
    "# test_data = data_model[(data.season == '2020-2021')]\n",
    "\n",
    "train_data_catboost = data_catboost[(data.season == '2017-2018') | (data.season == '2018-2019') | (data.season == '2019-2020')]\n",
    "test_data_catboost = data_catboost[(data.season == '2020-2021')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "072e0689",
   "metadata": {},
   "outputs": [],
   "source": [
    "def constant_train_predict(train_data, test_data, reg_parameter, features, target_variable, cols_to_standardize):\n",
    "    #get x and y data\n",
    "    X_train, X_test = train_data[model_features].copy(deep=True), test_data[model_features].copy(deep=True)\n",
    "    y_train, y_test = train_data[target_variable], test_data[target_variable]\n",
    "\n",
    "    #standardize\n",
    "    X_train, scaler = standardize(X_train, cols_to_standardize=cols_to_standardize)\n",
    "    X_test, _ = standardize(X_test, cols_to_standardize=cols_to_standardize, scaler=scaler)\n",
    "\n",
    "    #add constant\n",
    "    X_train = sm.add_constant(X_train)\n",
    "    X_test = sm.add_constant(X_test)\n",
    "\n",
    "    #train model\n",
    "    model = linear_model.GammaRegressor(fit_intercept=False, alpha = reg_parameter, max_iter = 20_000)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    #get predictions\n",
    "    train_preds = model.predict(X_train)\n",
    "    test_preds = model.predict(X_test)\n",
    "\n",
    "    train_pred_df = train_data[[\"date\", \"position\", \"player_id\", \"player\", \"npxg\", \"npg\"]].reset_index(drop=True).copy(deep=True)\n",
    "    train_pred_df[\"npxg_pred\"] = train_preds \n",
    "\n",
    "    test_pred_df = test_data[[\"date\", \"position\", \"player_id\", \"player\", \"npxg\", \"npg\"]].reset_index(drop=True).copy(deep=True)\n",
    "    test_pred_df[\"npxg_pred\"] = test_preds\n",
    "    \n",
    "    return train_pred_df, test_pred_df\n",
    "\n",
    "def catboost_train_predict(train_data, test_data, features, target_variable, cols_to_standardize, distribution=\"Poisson\"):\n",
    "\n",
    "    #get x and y data\n",
    "    X_train, X_test = train_data_catboost[features].copy(deep=True), test_data[features].copy(deep=True)\n",
    "    y_train, y_test = train_data_catboost[target_variable], test_data[target_variable]\n",
    "\n",
    "    #standardize\n",
    "    X_train, scaler = standardize(X_train, cols_to_standardize=cols_to_standardize)\n",
    "    X_test, _ = standardize(X_test, cols_to_standardize=cols_to_standardize, scaler=scaler)\n",
    "\n",
    "    # #catboost model\n",
    "    if distribution == \"Poisson\":\n",
    "        model = CatBoostRegressor(task_type=\"GPU\",\n",
    "                                    devices='0:1',\n",
    "                                    early_stopping_rounds = 50,\n",
    "                                    loss_function=\"Poisson\")\n",
    "    else:\n",
    "        model = CatBoostRegressor(task_type=\"GPU\",\n",
    "                                    devices='0:1',\n",
    "                                    early_stopping_rounds = 50,\n",
    "                                    loss_function='Tweedie:variance_power=1.99')\n",
    "    \n",
    "    #fit\n",
    "    model.fit(X_train,y=y_train, eval_set=(X_test, y_test), cat_features = cols_to_ohe,verbose=100)\n",
    "    \n",
    "    #get predictions\n",
    "    train_preds = model.predict(X_train)\n",
    "    test_preds = model.predict(X_test)\n",
    "\n",
    "    train_pred_df = train_data_catboost[[\"date\", \"position\", \"player_id\", \"player\", \"npxg\", \"npg\"]].reset_index(drop=True).copy(deep=True)\n",
    "    train_pred_df[\"npg_pred\"] = train_preds \n",
    "\n",
    "    test_pred_df = test_data_catboost[[\"date\", \"position\", \"player_id\", \"player\", \"npxg\", \"npg\"]].reset_index(drop=True).copy(deep=True)\n",
    "    test_pred_df[\"npg_pred\"] = test_preds\n",
    "    \n",
    "    return train_pred_df, test_pred_df, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8344299",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tune hyperparameters\n",
    "reg_grid = [0.00001, 0.0001,0.0005, 0.001,0.005, 0.01,0.05,0.1]\n",
    "grid_scores = []\n",
    "\n",
    "for reg_param in reg_grid:\n",
    "    print(f\"Tryin reg = {reg_param}\")\n",
    "    train_preds, test_preds = constant_train_predict(train_data, test_data, reg_parameter=reg_param)\n",
    "    \n",
    "    _,train_poisson_ll = calculate_log_likelihood(train_preds.npg,\n",
    "                                                           [train_preds.npxg_pred],\n",
    "                                                           distribution='Poisson',\n",
    "                                                           individual_scores=False)\n",
    "    \n",
    "    _,test_poisson_ll = calculate_log_likelihood(test_preds.npg,\n",
    "                                                           [test_preds.npxg_pred],\n",
    "                                                           distribution='Poisson',\n",
    "                                                           individual_scores=False)\n",
    "    \n",
    "    r2score_train = r2_score(y_true=train_preds.npg, y_pred=train_preds.npxg_pred)\n",
    "    r2score_test = r2_score(y_true=test_preds.npg, y_pred=test_preds.npxg_pred)\n",
    "        \n",
    "    grid_scores.append((reg_param, train_poisson_ll, test_poisson_ll, r2score_train, r2score_test))\n",
    "    \n",
    "grid_scores = pd.DataFrame(grid_scores, columns=[\"reg_parameter\",\"train_ll\", \"test_ll\", \"r2score_train\", \"r2score_test\"])\n",
    "grid_scores.sort_values(\"train_ll\", inplace=True)\n",
    "grid_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a4a0dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#final model and validation predictions\n",
    "train_preds, test_preds = constant_train_predict(train_data, test_data, 0.0005, model_features, target_variable, cols_to_standardize)\n",
    "\n",
    "#get ll metrics for test\n",
    "test_preds['poisson_ll'] = calculate_log_likelihood(test_preds.npg,\n",
    "                                                           [test_preds.npxg_pred],\n",
    "                                                           distribution='Poisson',\n",
    "                                                           individual_scores=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae40006",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Poisson catboost\n",
    "cat_train_preds, cat_test_preds, catboost_model = catboost_train_predict(train_data = train_data_catboost,\n",
    "                                                         test_data = test_data_catboost,\n",
    "                                                         features = catboost_features,\n",
    "                                                         target_variable = target_variable_cat,\n",
    "                                                         cols_to_standardize = cols_to_standardize)\n",
    "\n",
    "cat_test_preds['poisson_ll'] = calculate_log_likelihood(cat_test_preds.npg,\n",
    "                                                           [cat_test_preds.npg_pred],\n",
    "                                                           distribution='Poisson',\n",
    "                                                           individual_scores=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae6691f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_test_preds.poisson_ll.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92098f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_test_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2cc2935",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_score(y_pred=cat_test_preds.npg_pred, y_true=cat_test_preds.npg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c87adb59",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_test_preds.groupby([\"position\"],as_index=False)[[\"poisson_ll\", \"npg_pred\", \"npg\"]].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c6e672",
   "metadata": {},
   "outputs": [],
   "source": [
    "player_name = 'Harry Kane'\n",
    "data_to_check = cat_train_preds\n",
    "\n",
    "data_to_check[data_to_check.player == player_name].npg.value_counts(normalize=True).sort_index().plot(kind='bar', alpha=0.5)\n",
    "\n",
    "print(f\"N obs = {len(data_to_check[data_to_check.player == player_name])}\")\n",
    "# #regression\n",
    "# exps = test_preds[test_preds.player == 'Mohamed Salah'].npxg_pred.values\n",
    "# _x = np.arange(0, 8)\n",
    "# probs = poisson.pmf(_x,exps[:,np.newaxis])\n",
    "# plt.plot(probs.mean(axis=0), label=\"regression\")\n",
    "\n",
    "#catboost\n",
    "exps = data_to_check[data_to_check.player == player_name].npg_pred.values\n",
    "_x = np.arange(0, 8)\n",
    "probs = poisson.pmf(_x,exps[:,np.newaxis])\n",
    "plt.plot(probs.mean(axis=0), label=\"catboost\")\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0298ceda",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances = catboost_model.get_feature_importance()\n",
    "\n",
    "# Pair with feature names for clearer understanding\n",
    "features = catboost_features\n",
    "importance_dict = dict(zip(features, feature_importances))\n",
    "plt.bar(importance_dict.keys(), importance_dict.values())\n",
    "plt.xticks(rotation=90)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
